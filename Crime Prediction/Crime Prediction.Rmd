---
title: "Crime Prediction"
author: "Pradyumna Janga"
date: "August 31, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Crime Prediction

You are a Data Analyst working for the police department. You have been given a data set with a large number of variables and have been asked by the police chief to build a regression model to predict crime rates.

1. Clean variable_names and set the names of data to these clean names
2. The police chief is only interested in the following variables so create a new data frame with just these variables included: 'ViolentCrimesPerPop', 'pctUrban', 'agePct16t24', 'PctUnemployed', 'medIncome'
3. Check for correlations between medIncome and PctUnemployed. Plot these variables to confirm correlations
4. Split the data into training and testing sets using set.seed(123)
5. Build a linear regression model using pctUrban, agePct16t24 and whichever of the variables from question 3 is best correlated with ViolentCrimesPerPop
6. Predict the ViolentCrimesPerPop for the testing set
7. Calculate the R2 of the testing



```{r loadlibraries}
library(plyr)
library(dplyr)
library(ggplot2)
library(caTools)
```

Load the data into a variable and check its structure. Since there are 2 datasets in this case, we will load VARIABLE NAMES.CSV dataset first followed by the DATA.CSV dataset
```{r echo= FALSE, message = FALSE, loadvar}
rm(list = ls())
setwd("C:/Users/vj853t/Documents/DataScience/Case Study/Case Study 12")
var_name <- read.csv("~/DataScience/Case Study/Case Study 12/variable_names.csv", header = FALSE)
str(var_name)
```
Variable_names dataset has 3 variables with 128 observations. All the 3 variables are factors.

```{r echo = FALSE, loaddata}
data <- read.csv("~/DataScience/Case Study/Case Study 12/data.csv", header = FALSE)
str(data)
```
Data.csv dataset has 128 variables with 1994 observations.

The 1st column in the var_name has the list of all variables names and their descriptions. Since we need only the variable names, it needs some clean up and extraction of the names.

```{r echo = FALSE, cleanup}
var_name$clean = substr(var_name$V1, 4, 1000)
var_name$clean = gsub(":.+",'', var_name$clean)
head(var_name$clean)
```
The clean column in var_name has the extracted variable names which can be used as column names in data variable. Let us assign them and check the column names of data

```{r echo = FALSE, colnames}
names(data) <- var_name$clean
head(names(data))
```

# Data Filtering

The police cheif is only interested in 'ViolentCrimesPerPop', 'pctUrban', 'agePct16t24', 'PctUnemployed'& 'medIncome'. Filter the data to only have these columns and check the correlation between medIncome and PctUnemployed variables
```{r echo=FALSE, filtercolumns}
model_data <- data[, names(data) %in% c('ViolentCrimesPerPop', 'pctUrban',
                                        'agePct16t24', 'PctUnemployed', 'medIncome')]
head(model_data)
```

#Bivariate Analysis

Check for correlations between medIncome and PctUnemployed. Plot these variables to confirm correlations
```{r echo=FALSE, medIncomePctUnemployed}
cor(model_data$medIncome, model_data$PctUnemployed)
plot(model_data$medIncome, model_data$PctUnemployed, main = "Median Income per % of people 16 and over, in the labor force, and unemployed", 
     xlab = "Median Household Income",
     ylab = "% of people 16 and over, in the labor force and unemployed")
```

In the next step, check for correlations between medIncome and ViolentCrimesPerPop. Plot these variables to confirm correlations
```{r echo=FALSE, medIncomeViolentCrimesPerPop}
cor(model_data$medIncome, model_data$ViolentCrimesPerPop)
plot(model_data$medIncome, model_data$ViolentCrimesPerPop, 
     xlab = "Median Household Income",
     ylab = "Crimes per 100K population", main ="Median Income per total crimes")
```

From the correlation coefficient and the plots, it can be incurred that Median Income is negatively correlated with PctUnemployed and ViolentCrimesPerPop variables. This means that, an increase in Median Income is associated with a decrease in PctUnemployed and ViolentCrimesPerPop variables. This correlation actualy makes sense because the more the mdedian income per house hold indicates that there are more number of people who are actually employed and would find no reason or need to be involved in any crimes.


```{r echo=FALSE, PctUnemployedViolentCrimesPerPop}
cor(model_data$PctUnemployed, model_data$ViolentCrimesPerPop)

plot(model_data$PctUnemployed, model_data$ViolentCrimesPerPop, 
     xlab = "% of Unemployed Population",
     ylab = "Crimes per population", main ="% of Unemployed Population per Total amount of crimes per 100K population")
```

```{r echo=FALSE, PctUnemployedagePct16t24}
cor(model_data$PctUnemployed, model_data$agePct16t24)
plot(model_data$PctUnemployed, model_data$agePct16t24, 
     xlab = "% of Unemployed Population",
     ylab = "% of population that is 16-24 in age", main ="% of Unemployed Population per % of population that is 16-24 in age")
```

It can also be incurred that PctUnemployed variable (% of people 16 and over, in the labor force and unemployed) is positively correlated with ViolentCrimesPerPop and agePct12t24 variables which means that an increase in PCtUnemployed is associated with an increase in ViolentCrimesPerPop and agePct12t24 variables. This does gives a lot of information about the reason for more crimes. As the number of teens who are forced into child labour increase, 

#Data Split for prediction
In order to be able to predict the crime rates, we would need to split the model into train and test samples. Train sample will be used to create the data model and test sample will be used to test the data model that has been created. The goodness of the data model can be calculated by determining the R^2 value. R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.


Before splitting the dataset, let us set the seed to 123 so that it produces the same result even after multiple iterations. Also, the data will be split with a SPLITRATIO of 0.8 which means one part of the set contains 80% of the entire data and the other part will contain 20% of the entire data. In this case, the 80% of the data will be used as the training set and the 20% will be used to test the data model.

```{r echo = FALSE, splitdata}
set.seed(123)
split = sample.split(model_data$ViolentCrimesPerPop, SplitRatio = 0.8)

data_train <- model_data[split,] 
data_test <- model_data[!split,]
glimpse(data_train)
glimpse(data_test)
```

As mentioned above, training dataset contains 1595 observation i.e., 80% of the 1994 observations (entire dataset) and test dataset contains 399 which constitute to the remaining 20%. Since setseed function has been used while splitting, the values in the training and tet datasets will remain constant even after executing the program several times. This helps in getting the same R-Squared value every single time. If the setseed function is not used, the datasets will eb split with different values every time which in turn results in variable R-Squared value.

#Data MOdelling
As per the requirement, once need to build a linear regression model using pctUrban, agePct16t24 and whichever of the variables are best correlated with ViolentCrimesPerPop. From the correlation, we can see that MedIncome and PctUnemployed are more associated with ViolentCrimesPerPop. Even though the correlation with MedIncome is negative, it makes a statement saying that the higher the MedIncome, the lower will be the ViolentCrimesPerPop. This gives a strong reason to include that variable in the model.

However, variables agePct16t24 and PctUrban are very lightly correlated with ViolentCrimesPerPop. Infact the correlation is almost less than 10%. We can try creating a model in 2 different ways, 
1. Including variables agePct16t24 and PctUrban and
2. Excluding variables agePct16t24 and PctUrban

Based on the R-Squared value, we can determine the necessity of these variables. Let us use logistic regression as our data model. 
```{r echo=FALSE, modelcreate}
model = lm(formula = ViolentCrimesPerPop ~ medIncome + PctUnemployed + pctUrban + agePct16t24, data = data_train)
summary(model)
```

The data model has been created using logistic regression. Now, let us try to predict the violentcrimesperpop variable using the data model we just created with the Test dataset that has been created. The goodness of our prediction can only be determined by the R-Squared value. In order to determine the R-Squared value, 

```{r echo=FALSE,predictmodel}
test_predicted_data <- predict(model, newdata = data_test)
ss_residual <- sum((test_predicted_data - data_test$ViolentCrimesPerPop)^2)
ss_total <- sum((data_test$ViolentCrimesPerPop - mean(data_test$ViolentCrimesPerPop))^2)
r_square <- 1 - ss_residual/ss_total
r_square
```

R-Squared value value is only 0.29 which means that the model has not fit entirely well.

Now, let us remove the vairbles agePct16t24 and PctUrban and try to predict the crimes. 
```{r echo=FALSE, new_modelcreate}
model = lm(formula = ViolentCrimesPerPop ~ medIncome + PctUnemployed, data = data_train)
test_predicted_data <- predict(model, newdata = data_test)
ss_residual <- sum((test_predicted_data - data_test$ViolentCrimesPerPop)^2)
ss_total <- sum((data_test$ViolentCrimesPerPop - mean(data_test$ViolentCrimesPerPop))^2)
r_square <- 1 - ss_residual/ss_total
r_square
```

The R-squared value is little lower compared to the case where we had both agePct16t24 and PctUrban variables. This means that we need more statistically significant variables in order to make the prediction much more accurate and have a higher R-Squared value.